{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZG1JPaFUNcxf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1=pd.read_csv(\"E:/ANALYTICS TRAINING/FINANCE_AUDIT/FINANCE_ANALYTICS/DATA/Pd010419_modified1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='Orange'> Pandas - Merge / Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S No', 'MKT', 'SERIES', 'SYMBOL', 'SECURITY', 'Industry', 'PREV_CL_PR',\n",
       "       'OPEN_PRICE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da1_1=da1.iloc[0:5,0:8]\n",
    "da1_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  8,  9, 10, 11, 12, 13, 14, 15, 16])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=np.concatenate([np.array([1, 3]), np.array(list(range(8,17)))])\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MKT', 'SYMBOL', 'HIGH_PRICE', 'LOW_PRICE', 'CLOSE_PRICE', 'NET_TRDVAL',\n",
       "       'NET_TRDQTY', 'IND_SEC', 'TRADES', 'HI_52_WK', 'LO_52_WK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da1_2=da1.iloc[[0,1,2,5],cols]\n",
    "da1_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Subbi.DESKTOP-L4TAD5C\\AppData\\Local\\Temp\\ipykernel_8988\\1809072913.py:4: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  da1_2.loc[0,\"HIGH_PRICE\"]=\"\"\n"
     ]
    }
   ],
   "source": [
    "#da1_1 Industry col 3rd row and \n",
    "#da1_2 High_price col 1st row made empty\n",
    "da1_1.loc[2,\"Industry\"]=\" \"\n",
    "da1_2.loc[0,\"HIGH_PRICE\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner join\n",
    "da1_Ij=pd.merge(da1_1,da1_2,on=\"SYMBOL\",how=\"inner\")\n",
    "da1_Ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Ij.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner join -with more than one variable\n",
    "da1_Ij2=pd.merge(da1_1,da1_2,on=[\"SYMBOL\",\"MKT\"], how=\"inner\")\n",
    "da1_Ij2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Ij2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left join -with more than one variable\n",
    "da1_Lj=pd.merge(da1_1,da1_2,on=[\"SYMBOL\",\"MKT\"], how=\"left\")\n",
    "da1_Lj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Lj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Right join -with more than one variable\n",
    "da1_Rj=pd.merge(da1_1,da1_2,on=[\"SYMBOL\",\"MKT\"], how=\"right\")\n",
    "da1_Rj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Rj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outer join -with more than one variable\n",
    "da1_Oj=pd.merge(da1_1,da1_2,on=[\"SYMBOL\",\"MKT\"], how=\"outer\")\n",
    "da1_Oj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Oj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross join -with one variable from each data set\n",
    "da1_Cj=pd.merge(da1_1[[\"Industry\"]],da1_2,how=\"cross\")\n",
    "da1_Cj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Cj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'> Pandas - Lead / Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       383.05\n",
       "1      1492.75\n",
       "2       765.60\n",
       "3      2915.65\n",
       "4      7158.80\n",
       "        ...   \n",
       "495      61.15\n",
       "496    1505.70\n",
       "497     455.00\n",
       "498     230.60\n",
       "499    1322.05\n",
       "Name: CLOSE_PRICE, Length: 500, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da1[\"CLOSE_PRICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1       383.05\n",
       "2      1492.75\n",
       "3       765.60\n",
       "4      2915.65\n",
       "        ...   \n",
       "495     146.85\n",
       "496      61.15\n",
       "497    1505.70\n",
       "498     455.00\n",
       "499     230.60\n",
       "Name: CLOSE_PRICE, Length: 500, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#da1[''CLOSE_PRICE_Lag]=\n",
    "da1[\"CLOSE_PRICE\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Auto=da1[da1['Industry']==\"AUTOMOBILE\"].sort_values(by='SYMBOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Auto=da1.loc[da1['Industry']==\"AUTOMOBILE\"].sort_values(by='SYMBOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Auto['close_lag']=da1_Auto[\"CLOSE_PRICE\"].shift(1)\n",
    "da1_Auto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Auto['close_diff']=da1_Auto[\"CLOSE_PRICE\"]-da1_Auto['close_lag']\n",
    "da1_Auto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Auto['close_per_diff']=100*da1_Auto['close_diff']/da1_Auto[\"CLOSE_PRICE\"]\n",
    "da1_Auto.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Auto.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da1_Auto['close_lead']=da1_Auto[\"CLOSE_PRICE\"].shift(-1)\n",
    "da1_Auto.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wtECGhdENcyD"
   },
   "source": [
    "## <font color='orange'> Pandas - Data Cleaning\n",
    "\n",
    "Data cleaning might be required when the given data set has\n",
    "\n",
    " * Empty cells\n",
    "\n",
    " * Data in wrong format\n",
    "\n",
    " * Wrong data\n",
    "\n",
    " * Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DmHehRYZNcyD"
   },
   "source": [
    "### <font color='pink'> Pandas - Handling Empty Cells (NA / NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fltsSxcHNcyE",
    "outputId": "c8c08601-43d2-4d55-eca2-354e0297d506"
   },
   "outputs": [],
   "source": [
    "df_mv = pd.read_csv(r'E:\\ANALYTICS TRAINING\\Data\\MissingValuesData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na1=np.where(pd.isnull(df_mv))\n",
    "\n",
    "print(na1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mv.iloc[na1[0],na1[1]]\n",
    "\n",
    "#or\n",
    "\n",
    "for row, col in zip(na1[0], na1[1]):\n",
    "    print(f\"Row {row}, Column {df_mv.columns[col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.dropna()\n",
    "print(new_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Missing values\n",
    "print(np.array(na1[0]).size)\n",
    "\n",
    "print(np.array(na1[1]).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(pd.isnull(df_mv[\"All Time Peak\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(pd.isnull(df_mv[\"All Time Peak\"]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv[\"All Time Peak\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv[\"All Time Peak\"].mean(skipna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mv[\"All Time Peak\"].std(skipna=False)\n",
    "df_mv[\"All Time Peak\"].std(skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In quantile() No Need for skipna \n",
    "df_mv[\"All Time Peak\"].quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l9Ue48yNcyF"
   },
   "source": [
    "### <font color='yellowgreen'> Note Remove Rows\n",
    "\n",
    "One way to deal with empty cells is to remove rows that contain empty cells.\n",
    "\n",
    "**If the data set is sufficiently large then removing a few rows may not have a big impact on the result**   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l9Ue48yNcyF"
   },
   "source": [
    "### <font color='yellowgreen'> Note - Remove Rows - Save - New or Existing   \n",
    "Remove all rows with NULL values and save it as a new DF \n",
    "\n",
    "or\n",
    "\n",
    "If you want to change the original DataFrame, use the inplace = True argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycn4ZS34NcyG",
    "outputId": "de5cdd56-9ff9-4ae1-94b3-e6753c7d9c04"
   },
   "outputs": [],
   "source": [
    "df_mv1 = df_mv.dropna()\n",
    "print(df_mv1)# .to_string())\n",
    "\n",
    "#df = pd.read_csv('C://Users//lmohan2//Desktop//New folder//test//dirtydata.csv')\n",
    "#df.dropna(inplace = True)\n",
    "#print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2edL5SWgNcyI"
   },
   "source": [
    "### <font color='pink'> Replace Empty cells - Only For a Specified Columns\n",
    "The example above replaces all empty cells in the whole Data Frame.\n",
    "\n",
    "To only replace empty values for one column, specify the column name for the DataFrame:\n",
    "\n",
    "Replace NULL values in the \"Calories\" columns with the number 130:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDrZ31jXNcyI"
   },
   "outputs": [],
   "source": [
    "#df_mv[\"Peak\"].fillna(20, inplace = True)\n",
    "\n",
    "df_mv.fillna({\"Peak\":20, \"All Time Peak\":100},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nq0Ka9bUNcyH"
   },
   "source": [
    "### <font color='pink'> Replace Empty Values - In the Entire data set\n",
    "\n",
    "The fillna() method can be used to replace empty cells (in the whole of df) with a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKAIbd6ONcyH"
   },
   "outputs": [],
   "source": [
    "df_mv.fillna(value = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NYOJKnhNcyJ"
   },
   "source": [
    "### <font color='pink'> Replace Using Mean, Median, or Mode\n",
    "\n",
    "For a numeric column than has empty cells, it is possible to fill with some summaries like, mean, median\n",
    "\n",
    "Calculate the MEAN, and replace any empty values with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fz6-gZvfNcyJ"
   },
   "outputs": [],
   "source": [
    "#replace empty values with mean\n",
    "pe_me = df_mv[\"Peak\"].mean()\n",
    "df_mv.fillna({\"Peak\":pe_me}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANs1AS6qNcyL"
   },
   "source": [
    "### <font color='pink'> Cleaning Data of Wrong Format\n",
    "\n",
    "If a column is in a wrong format, then it may not be possible to analyze data. Either we may remove such a column or covert it into the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPeYa92JNcyM",
    "outputId": "0d0157ac-a71e-4cb0-a742-f2328709baf9"
   },
   "outputs": [],
   "source": [
    "df_uncle = pd.read_csv(r'E:\\ANALYTICS TRAINING\\Data\\UncleanedData_Eg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_uncle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellowgreen'> **Time Date Format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle['Date'] = pd.to_datetime(df_uncle['Date'])\n",
    "df_uncle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellowgreen'> **Typo Errors / Wrong values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle['Duration'] = pd.to_numeric(df_uncle['Duration'])\n",
    "df_uncle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle['Duration1'] = pd.to_numeric(df_uncle['Duration'],errors='coerce')\n",
    "df_uncle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle['Duration1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7WOTRlsNcyN"
   },
   "source": [
    "<font color='yellowgreen'> **Conditional - Data Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6h5xlN0NcyQ"
   },
   "outputs": [],
   "source": [
    "for x in df_uncle.index:\n",
    "  if df_uncle.loc[x, \"Duration1\"] > 100:\n",
    "    df_uncle.loc[x, \"Duration1\"] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle[\"Duration1\"] #NA values will not be altered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-NLgF71NcyR"
   },
   "source": [
    "<font color='yellowgreen'> **Removing Rows**\n",
    "\n",
    "It is possible to remove the rows that contains wrong data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle[\"Duration2\"]=df_uncle[\"Duration1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7A54L8DaNcyR"
   },
   "outputs": [],
   "source": [
    "for x in df_uncle.index:\n",
    "  if df_uncle.loc[x, \"Duration2\"] > 90:\n",
    "    df_uncle.drop(x, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle[\"Duration2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3qWXn83NcyS"
   },
   "source": [
    "### <font color='pink'> Locating Duplicates\n",
    "\n",
    "Some rows might have repeated values that may be due to unnoticed values like a candidate may be registered more than one time.\n",
    "\n",
    "The duplicated() method can be used t0 check this that returns a Boolean values for each row (True for every row that is a duplicate, othwerwise False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle = pd.read_csv(r'E:\\ANALYTICS TRAINING\\Data\\UncleanedData_Eg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JusZU9djNcyS",
    "outputId": "9ef7609a-f9fc-4c56-af61-0f48190afb39"
   },
   "outputs": [],
   "source": [
    "print(df_uncle.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df_uncle.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle.iloc[[11,12],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JusZU9djNcyS",
    "outputId": "9ef7609a-f9fc-4c56-af61-0f48190afb39"
   },
   "outputs": [],
   "source": [
    "print(df_uncle.duplicated(\"Duration\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5coTDg0vNcyT"
   },
   "source": [
    "### <font color='pink'> Removing Duplicates\n",
    "\n",
    "use the drop_duplicates() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHC1LYfhNcyT"
   },
   "outputs": [],
   "source": [
    "df_uncle.drop_duplicates(inplace = True) #whole DF, remove the repeated row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uncle[\"Pulse\"].drop_duplicates(inplace = True) #specific column, remove the repeated row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_uncle[\"Pulse\"])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
